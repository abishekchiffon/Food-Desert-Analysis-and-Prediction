---
title: "Project2 - GWU Intro to Data Science DATS 6101"
author: "Keerthana"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r base_lib}
loadPkg("ggplot2")
```


## Initialize

```{r}
df <- data.frame(read.csv("FoodDesert2015.csv")) 
head(df)
#summary(df)
``` 

############################################################
# Question 2 : Can we quantify the impact of the "PovertyRate" and "Group Quarters" on the likelihood of a census tract being classified as a food desert?
############################################################


## Effect of Group quarters by food desert:

```{r crosstable}
FooddesertGroupquarterstable = xtabs(~ LILATracts_1And10 + GroupQuartersFlag, data = df)
FooddesertGroupquarterstable
```

### Chi squared test

We can then quickly run a chi-squared test to see if the two are independent (or same frequency distribution).  
```{r chisq}
chisqres = chisq.test(FooddesertGroupquarterstable)
chisqres
```

From the small p-value of `r chisqres$p.value`, we conclude that the food desert and non food desert subgroups have different frequency distribution among the Groupquarters. This is just another way of saying that the group quarters and Fooddesrts are NOT independent. 

## Effect of poverty rate by food desert:

### T -test

```{r ttest}
food_desert_group <- subset(df, LILATracts_1And10 == 1)
non_food_desert_group <- subset(df, LILATracts_1And10 == 0)

# Perform t-test
t_test_result <- t.test(food_desert_group$PovertyRate, non_food_desert_group$PovertyRate)

# Display the results
print(t_test_result)
```

The p-value is extremely small, indicating strong evidence against the null hypothesis. In practical terms, it suggests that there is a highly significant difference in the mean PovertyRate between food desert and non-food desert census tracts.

## Model 1: PovertyRate + GroupQuartersFlag

```{r model}
df$LILATracts_1And10 <- factor(df$LILATracts_1And10)
df$GroupQuartersFlag <- factor(df$GroupQuartersFlag)

model <- glm(LILATracts_1And10 ~ PovertyRate + GroupQuartersFlag, family = binomial(link = "logit"), data = df)

summary(model)
```
For a one-unit increase in the PovertyRate, the log-odds of the response variable being 1 increase by 0.055816. The coefficient is highly significant (p-value < 2e-16).

GroupQuartersFlag of 1 is associated with a decrease of 0.643663 in the log-odds of the response variable being 1. The coefficient is significant (p-value = 8e-06).

AIC is low here compared to other models.

All the coefficients are found significant (small p-values). Poverty rate have positive effects on Food desert chance (Food desert = 1), while GroupQuartersflag negatively affect the Food deserts likelihood.

```{r results='markup'}
xkabledply(model, title = paste("Logistic Regression :", format(formula(model)) ))
```

##########################################3
##########################################

```{r growthDecayFactors, results='markup', collapse=F}
expcoeff = exp(coef(model10))
expcoeff
#xkabledply(as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" )
```

for a one-unit increase in PovertyRate, the odds of the event (typically the event being predicted by the logistic regression) increase by a factor of approximately 1.0574030.

for a one-unit increase in GroupQuartersFlag1, the odds of the event (typically the event being predicted by the logistic regression) decrease by a factor of approximately 0.5253647.


```{r}
#install.packages("car")
df$Urban <- as.factor(df$Urban)
df$LowIncomeTracts <- as.factor(df$LowIncomeTracts)
library(car)

# Assuming df is your data frame with predictor variables
# Replace 'df' with your actual data frame and include only the predictor variables

# Fit a linear regression model (assuming 'response_variable' is your response variable)
model <- lm(PovertyRate ~ MedianFamilyIncome + LowIncomeTracts + TractSNAP + TractHUNV + laasian1 + TractSeniors + TractWhite, data = df)

# TractWhite+TractBlack+TractAsian+TractNHOPI+TractAIAN+TractOMultir+TractHispanic+lawhite10+lawhite10share+lablack10+lablack10share+laasian10+laasian10share+lanhopi10+lanhopi10share+laaian10+laaian10share+laomultir10+laomultir10share+lahisp10+lahisp10share

# Calculate VIF
vif_values <- car::vif(model)

# Print VIF values
print(vif_values)
```

## Model 2: PovertyRate

```{r model1}
df$Urban <- factor(df$Urban)

model1 <- glm(LILATracts_1And10 ~ PovertyRate, family = binomial(link = "logit"), data = df)

summary(model1)
```

coefficients are found significant (small p-values). Poverty rate have positive effects on Food desert chance (Food desert = 1)

AIC greater than model 1.

## Model 3: GroupQuartersFlag

```{r model2}

model2 <- glm(LILATracts_1And10 ~ GroupQuartersFlag, family = binomial(link = "logit"), data = df)

summary(model2)
```

coefficients are found significant (small p-values). AIC greater than model 2.

## Model 4: PovertyRate : Urban

```{r model1}

model4 <- glm(LILATracts_1And10 ~ PovertyRate * Urban, family = binomial(link = "logit"), data = df)

summary(model4)
```

The interaction effect. It represents how the effect of PovertyRate on the log-odds changes when Urban is 1. In this case, the log-odds decrease by 0.039517.

A negative interaction term suggests that the effect of PovertyRate on the log-odds is weakened when Urban is 1.

* When Urban is 0 (not an urban area):
An increase in PovertyRate by one unit is associated with a larger increase in the log-odds of the response variable being 1.

* When Urban is 1 (urban area):

An increase in PovertyRate by one unit is associated with a smaller increase in the log-odds of the response variable being 1.

In simpler terms, the impact of PovertyRate on the response variable depends on whether the area is urban or not. The negative coefficient indicates that the effect of PovertyRate is somewhat mitigated in urban areas compared to non-urban areas.

## Model 5: PovertyRate : GroupQuartersFlag

```{r model1}

model5 <- glm(LILATracts_1And10 ~ PovertyRate * GroupQuartersFlag, family = binomial(link = "logit"), data = df)

summary(model5)
```

The interaction effect. It represents how the effect of PovertyRate on the log-odds changes when GroupQuartersFlag is 1. In this case, the log-odds decrease by 0.0314293.

* In areas without group quarters (GroupQuartersFlag is 0), 
an increase in PovertyRate is associated with a relatively larger increase in the log-odds of the response variable being 1.

* In areas with group quarters (GroupQuartersFlag is 1), 
the positive impact of PovertyRate on the log-odds is moderated, resulting in a smaller increase in the log-odds.


## Model 6: GroupQuartersFlag : Urban

```{r model2}

model6 <- glm(LILATracts_1And10 ~ GroupQuartersFlag * Urban, family = binomial(link = "logit"), data = df)

summary(model6)
```

In non-urban areas, the presence of group quarters (GroupQuartersFlag1) is not statistically significant in predicting the log-odds of the response variable being 1.

In urban areas, the presence of group quarters (GroupQuartersFlag1) is associated with an increase in the log-odds of the response variable being 1. However, the statistical significance of this effect is not strong based on the p-value.

## Model 7: GroupQuartersFlag : Urban : Povertyrate

```{r model2}

model6 <- glm(LILATracts_1And10 ~ GroupQuartersFlag + Urban + PovertyRate, family = binomial(link = "logit"), data = df)

summary(model6)
```

## Model 8: PovertyRate ~ GroupQuarters

```{r model}

model8 <- lm(PovertyRate ~ GroupQuartersFlag, data = df)

summary(model8)
```


- How is Groupquarters associated with Poverty rate:

```{r code8, include=FALSE}

# data_outliers <- ezids::outlierKD2(df, PovertyRate, rm = TRUE, boxplt = TRUE, qqplt = TRUE)
data_outliers <- df
GroupQuarters_Poverty <- data_outliers[data_outliers$GroupQuartersFlag == 1, c("GroupQuartersFlag", "PovertyRate")]
NonGroupQuarters_Poverty <- data_outliers[data_outliers$GroupQuartersFlag == 0, c("GroupQuartersFlag", "PovertyRate")]

```

```{r code9, echo=TRUE}

data2 = data.frame()
Percentage_GroupQuarters_Poverty = sum(GroupQuarters_Poverty$PovertyRate)/(sum(nrow(GroupQuarters_Poverty)+ nrow(NonGroupQuarters_Poverty)))*100
Percentage_NonGroupQuarters_Poverty = sum(NonGroupQuarters_Poverty$PovertyRate)/(sum(nrow(GroupQuarters_Poverty)+ nrow(NonGroupQuarters_Poverty)))*100
data2 <- rbind(data2, Percentage_GroupQuarters_Poverty)
data2 <- rbind(data2, Percentage_NonGroupQuarters_Poverty)
GroupQuartersFlag = c(1,0)
data2 <- cbind(data2, GroupQuartersFlag)
colnames(data2) <- c('Percentage', 'GroupQuartersFlag')

library(ggplot2)
ggplot(data2, aes(x = factor(GroupQuartersFlag), y = Percentage, fill = factor(GroupQuartersFlag))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("0" = "pink", "1" = "lightblue")) +
  labs(title = "Percentage of Poverty in group quarters",
       fill = "GroupQuartersFlag") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

## Model 9: PovertyRate ~ medianFamilyIncome : Urban

```{r model}

model9 <- lm(PovertyRate ~ MedianFamilyIncome * Urban, data = df)
summary(model9)
```


```{r}

ggplot(df, aes(x = MedianFamilyIncome, y = PovertyRate, color)) +
  geom_point() +
  labs(x = "Median Family Income", y = "Poverty Rate") +
  theme_minimal()

ggplot(df, aes(x = factor(Urban), y = MedianFamilyIncome, fill = factor(Urban))) +
  geom_boxplot() +
  labs(x = "Urban", y = "Median Family Income", title = "Box Plot of Median Family Income by Urban/Rural") +
  theme_minimal()

```

```{r}
data_outliers <- ezids::outlierKD2(df, PovertyRate, rm = TRUE, boxplt = TRUE, qqplt = TRUE)
```

## Model 10: PovertyRate ~ TractSNAP

```{r model}

model10 <- lm(PovertyRate ~ TractSNAP, data = df)
summary(model10)
#df$TractSNAP
```

```{r}

ggplot(df, aes(x = TractSNAP, y = PovertyRate, color = 'g')) +
  geom_point() +
  labs(x = "TractSNAP", y = "Poverty Rate") +
  theme_minimal()
```

## Model 11: PovertyRate ~ LowIncomeTracts

```{r model}
df$LowIncomeTracts = as.factor(df$LowIncomeTracts)
model11 <- lm(PovertyRate ~ LowIncomeTracts, data = df)
summary(model11)
#df$TractSNAP
```

```{r code8, include=FALSE}

# data_outliers <- ezids::outlierKD2(df, PovertyRate, rm = TRUE, boxplt = TRUE, qqplt = TRUE)
data_outliers <- df
LowIncomeTracts_Poverty <- data_outliers[data_outliers$LowIncomeTracts == 1, c("LowIncomeTracts", "PovertyRate")]
NonLowIncomeTracts_Poverty <- data_outliers[data_outliers$LowIncomeTracts == 0, c("LowIncomeTracts", "PovertyRate")]

```

```{r code9, echo=TRUE}

data2 = data.frame()
Percentage_LowIncomeTracts_Poverty = sum(LowIncomeTracts_Poverty$PovertyRate)/(sum(nrow(LowIncomeTracts_Poverty)+ nrow(NonLowIncomeTracts_Poverty)))*100
Percentage_NonLowIncomeTracts_Poverty = sum(NonLowIncomeTracts_Poverty$PovertyRate)/(sum(nrow(LowIncomeTracts_Poverty)+ nrow(NonLowIncomeTracts_Poverty)))*100
data2 <- rbind(data2, Percentage_LowIncomeTracts_Poverty)
data2 <- rbind(data2, Percentage_NonLowIncomeTracts_Poverty)
LowIncomeTracts = c(1,0)
data2 <- cbind(data2, LowIncomeTracts)
colnames(data2) <- c('Percentage', 'LowIncomeTracts')

library(ggplot2)
ggplot(data2, aes(x = factor(LowIncomeTracts), y = Percentage, fill = factor(LowIncomeTracts))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("0" = "lightgreen", "1" = "lightblue")) +
  labs(title = "Percentage of Poverty in LowIncomeTracts",
       fill = "LowIncomeTracts") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

## Model 12: PovertyRate ~ LILATracts_1And10

```{r model}

model12 <- lm(PovertyRate ~ LILATracts_1And10, data = df)
summary(model12)
#df$TractSNAP
```

```{r model}

modelVIF <- lm(PovertyRate ~ MedianFamilyIncome + LowIncomeTracts + TractSNAP + TractHUNV + laasian1 + TractSeniors + TractWhite, data = df)
summary(modelVIF)
#df$TractSNAP
```

```{r}
library(car)


# Observed vs. Predicted plot
#plot(modelVIF, col="blue", pch=16, main="Observed vs. Predicted", cex.main=1.2, col.main="red")

plot_data <- data.frame(
  Observed = df$PovertyRate,  # Replace 'df' with your actual data frame
  Predicted = predict(modelVIF)
)

# Create the observed vs. predicted plot
plot(plot_data$Predicted, plot_data$Observed, 
     main = "Observed vs. Predicted",
     xlab = "Predicted Values",
     ylab = "Observed Values",
     col = "blue", pch = 16)

# Add a reference line for a perfect fit (y = x)
abline(0, 1, col = "red")

```

```{r}
library(car)

# Compute influence measures
influence_data <- influence.measures(modelVIF)

# Cook's distance
cooksd <- influence_data$infmat[, "cook.d"]

# Studentized residuals
student_resid <- rstandard(modelVIF)

# Leverage vs. Residuals plot
plot(hatvalues(modelVIF), student_resid,
     main = "Residuals vs. Leverage",
     xlab = "Leverage",
     ylab = "Studentized Residuals",
     pch = 16,
     col = ifelse(cooksd > 4/nrow(df), "red", "blue"))

# Identify influential points using Cook's distance
influential_points_cook <- which(cooksd > 4/nrow(df))

# Print influential points identified by Cook's distance
cat("Influential Points (Cook's Distance):", influential_points_cook, "\n")

```

## Normality of Median family income

```{r}
hist(df$MedianFamilyIncome, main = "Histogram of Median Family Income", xlab = "Median Family Income")

# Check normality with a Q-Q plot
qqnorm(df$MedianFamilyIncome, main = "Q-Q Plot of Median Family Income")
qqline(df$MedianFamilyIncome, col = 2)

# Check normality with the Shapiro-Wilk test
shapiro.test(df$MedianFamilyIncome)
```

## Normality of Poverty rate

```{r}
hist(df$PovertyRate, main = "Histogram of PovertyRate", xlab = "PovertyRate")

# Check normality with a Q-Q plot
qqnorm(df$PovertyRate, main = "Q-Q Plot of PovertyRate")
qqline(df$PovertyRate, col = 2)

# Check normality with the Shapiro-Wilk test
shapiro.test(df$PovertyRate)
```


############################################################
# What specific factors most significantly contribute to a tract being classified as a food desert?
############################################################

```{r}
df_subset = subset(df, select = -c(CensusTract,State,County,LowIncomeTracts))
df_subset$Urban = as.factor(df_subset$Urban)
df_subset$LILATracts_halfAnd10 = as.factor(df_subset$LILATracts_halfAnd10)
df_subset$LILATracts_1And20 = as.factor(df_subset$LILATracts_1And20)
df_subset$LILATracts_Vehicle = as.factor(df_subset$LILATracts_Vehicle)
df_subset$HUNVFlag = as.factor(df_subset$HUNVFlag)
# df_subset$LowIncomeTracts = as.factor(df_subset$LowIncomeTracts)
df_subset$LA1and10 = as.factor(df_subset$LA1and10)
df_subset$LAhalfand10 = as.factor(df_subset$LAhalfand10)
df_subset$LA1and20 = as.factor(df_subset$LA1and20)
df_subset$LATracts_half = as.factor(df_subset$LATracts_half)
df_subset$LATracts1 = as.factor(df_subset$LATracts1)
df_subset$LATracts10 = as.factor(df_subset$LATracts10)
df_subset$LATracts20 = as.factor(df_subset$LATracts20)
df_subset$LATractsVehicle_20 = as.factor(df_subset$LATractsVehicle_20)

```


```{r forward_step_LG}
# Load necessary library
library(stats)

# Assuming your data is in a dataframe called 'data' and the response variable is 'response'
# Replace 'response' with your actual response variable name

# Initial model with only the intercept (no predictors)
initial_model <- glm(LILATracts_1And10 ~ 1, data = df_subset, family = binomial(link = "logit"))

# Full model with all potential predictors
full_model <- glm(LILATracts_1And10 ~ ., data = df_subset, family = binomial(link = "logit"))

# Perform stepwise forward selection
stepwise_model <- step(initial_model, scope = list(lower = initial_model, upper = full_model), direction = "forward")

# View the summary of the selected model
summary(stepwise_model)

```





########### Trial omit


```{r leaps}
loadPkg("pROC") 
loadPkg("aod") 
loadPkg("leaps")
reg.leaps <- regsubsets(y~., data = df_subset, nbest = 1, method = "exhaustive", really.big=T)  # leaps, 
plot(reg.leaps, scale = "adjr2", main = "Adjusted R^2")
plot(reg.leaps, scale = "bic", main = "BIC")
plot(reg.leaps, scale = "Cp", main = "Cp")
```

important variable:

GroupQuartersFlag
PCTGQTRS
HUNVFlag
Poverty rate
MedianFamilyIncome
LATracts1
LATractsVehicle_20

## Model glm 1

```{r}
model_glm1 <- glm(LILATracts_1And10 ~ GroupQuartersFlag + PovertyRate + MedianFamilyIncome + LATracts1 + HUNVFlag + LATractsVehicle_20, family = binomial(link = "logit"), data = df_subset)

summary(model_glm1)

predict_model <- predict(model_glm1, df_subset, type='response')
df_subset$pred_model_glm1 <- ifelse(predict_model >= 0.5, 1, 0)
accuracy <- mean((df_subset$pred_model_glm1)== (df_subset$LILATracts_1And10))

accuracy

```

```{r}

cm = table(df_subset$LILATracts_1And10,model_glm1$fitted.values>.5)
xkabledply( table(df_subset$LILATracts_1And10,model_glm1$fitted.values>.5), title = "Confusion matrix from Logit Model" )
round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)
```

The total accuracy (using the default cutoff of 0.5) is `r round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)`% which is pretty decent.

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

ROC and AUC measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The AUC is always between 0.5 and 1.  

```{r }
loadPkg("pROC")
df_demo = df_subset['LILATracts_1And10']
df_demo$prob1=predict(model_glm1, type = c("response")) # Add new column of predicted probabilities
h <- roc(LILATracts_1And10~prob1, data=df_demo)
auc(h)
plot(h)
```

## Model glm 2


```{r}
model_glm2 <- glm(LILATracts_1And10 ~ OHU2010 + LA1and20 + LATracts10 + GroupQuartersFlag + HUNVFlag * LATractsVehicle_20 + MedianFamilyIncome * PovertyRate + lalowi1share + lakids1share + lahisp1share + laseniors10share + lawhite1share + lablack1share + laaian1share + laomultir10share, family = binomial(link = "logit"), data = df_subset)

summary(model_glm2)

predict_model <- predict(model_glm2, df_subset, type='response')
df_subset$pred_model_glm2 <- ifelse(predict_model >= 0.5, 1, 0)
accuracy <- mean((df_subset$pred_model_glm2)== (df_subset$LILATracts_1And10))

accuracy

```

```{r}

cm = table(df_subset$LILATracts_1And10,model_glm2$fitted.values>.5)
xkabledply( table(df_subset$LILATracts_1And10,model_glm2$fitted.values>.5), title = "Confusion matrix from Logit Model" )
round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)
```

The total accuracy (using the default cutoff of 0.5) is `r round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)`% which is pretty decent.

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

ROC and AUC measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The AUC is always between 0.5 and 1.  

```{r }
loadPkg("pROC")
df_demo$prob2=predict(model_glm2, type = c("response")) # Add new column of predicted probabilities
h <- roc(LILATracts_1And10~prob2, data=df_demo)
auc(h)
plot(h)
```


## Model glm 4


```{r}
model_glm4 <- glm(LILATracts_1And10 ~ lahunv1share + Urban + lakids10 + lawhite1 + laseniors10 + lablack1 + laomultir1 + TractAsian + laaian1 + TractHUNV + TractWhite + lakids1 + TractOMultir + GroupQuartersFlag + PovertyRate + TractSNAP, family = binomial(link = "logit"), data = df_subset)

summary(model_glm4)

predict_model <- predict(model_glm4, df_subset, type='response')
df_subset$pred_model_glm4 <- ifelse(predict_model >= 0.5, 1, 0)
accuracy <- mean((df_subset$pred_model_glm4)== (df_subset$LILATracts_1And10))

accuracy

```

```{r}

cm = table(df_subset$LILATracts_1And10,model_glm4$fitted.values>.5)
xkabledply( table(df_subset$LILATracts_1And10,model_glm4$fitted.values>.5), title = "Confusion matrix from Logit Model" )
round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)
```

The total accuracy (using the default cutoff of 0.5) is `r round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)`% which is pretty decent.

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

ROC and AUC measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The AUC is always between 0.5 and 1.  

```{r }
loadPkg("pROC")
df_demo = df['LILATracts_1And10']
df_demo$prob4=predict(model_glm4, type = c("response")) # Add new column of predicted probabilities
h <- roc(LILATracts_1And10~prob4, data=df_demo)
auc(h)
plot(h)
```

```{r}
model_imp <- glm(LILATracts_1And10 ~ Urban + lahunv1share + lablack1 + lahisp1 + laomultir1 + laaian1 + lakids10 + lakids1 + laseniors10 + TractWhite + TractWhite + TractAsian + TractNHOPI + TractHispanic + TractHUNV + PovertyRate, family = binomial(link = "logit"), data = df)

summary(model_imp)

```


############################################################
# How does the model's performance vary across different demographic groups?
############################################################

## Urban

```{r model}
df_Urban <- subset(df, Urban == 1)
df_Urban$LILATracts_1And10 <- factor(df_Urban$LILATracts_1And10)
#df$GroupQuartersFlag <- factor(df$GroupQuartersFlag)

model_urbanWhite <- glm(LILATracts_1And10 ~ lawhite1 + lawhite1share + TractWhite, family = "binomial", data = df_Urban)
summary(model_urbanWhite)
```
```{r}

model_urbanBlack <- glm(LILATracts_1And10 ~ lablack1 + lablack1share + TractBlack, family = "binomial", data = df_Urban)
summary(model_urbanBlack)

cm = confusionMatrix( predict(kfit, type = "class"), reference = kyphosis[, "Kyphosis"] ) # from caret library
  # 
  cmaccu = cm$overall['Accuracy']
  
```

```{r}

model_urbanNHOPI <- glm(LILATracts_1And10 ~ lanhopi1 + lanhopi1share + TractNHOPI, family = "binomial", data = df_Urban)
summary(model_urbanNHOPI)

```

```{r}

model_urbanAsian <- glm(LILATracts_1And10 ~ laasian1 + laasian1share + TractAsian, family = "binomial", data = df_Urban)
summary(model_urbanAsian)

```

```{r}

model_urbanAian <- glm(LILATracts_1And10 ~ laaian1 + laaian1share + TractAIAN, family = "binomial", data = df_Urban)
summary(model_urbanAian)

```

```{r}

model_urbanomultir <- glm(LILATracts_1And10 ~ laomultir1 + laomultir1share + TractOMultir, family = "binomial", data = df_Urban)
summary(model_urbanomultir)

```

```{r}

model_urbanhispanic <- glm(LILATracts_1And10 ~ lahisp1 + lahisp1share + TractHispanic, family = "binomial", data = df_Urban)
summary(model_urbanhispanic)

```

```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
probwhite=predict(model_urbanWhite, type = "response" )
probblack=predict(model_urbanBlack, type = "response" )
probnhopi=predict(model_urbanNHOPI, type = "response" )
probasian=predict(model_urbanAsian, type = "response" )
probaian=predict(model_urbanAian, type = "response" )
probomultir=predict(model_urbanomultir, type = "response" )
probhisp=predict(model_urbanhispanic, type = "response" )

df_Urban$probwhite=probwhite
df_Urban$probblack=probblack
df_Urban$probnhopi=probnhopi
df_Urban$probasian=probasian
df_Urban$probaian=probaian
df_Urban$probomultir=probomultir
df_Urban$probhisp=probhisp

h1 <- roc(LILATracts_1And10~probwhite, data=df_Urban)
auc(h1) # area-under-curve prefer 0.8 or higher.

h2 <- roc(LILATracts_1And10~probblack, data=df_Urban)
auc(h2)
h3 <- roc(LILATracts_1And10~probnhopi, data=df_Urban)
auc(h3)
h4 <- roc(LILATracts_1And10~probasian, data=df_Urban)
auc(h4)
h5 <- roc(LILATracts_1And10~probaian, data=df_Urban)
auc(h5)
h6 <- roc(LILATracts_1And10~probomultir, data=df_Urban)
auc(h6)
h7 <- roc(LILATracts_1And10~probhisp, data=df_Urban)
auc(h7)

#plot(h)
# unloadPkg("pROC")
```

## Rural:

```{r modell}
df_rural <- subset(df, Urban == 0)
df_rural$LILATracts_1And10 <- factor(df_rural$LILATracts_1And10)
#df$GroupQuartersFlag <- factor(df$GroupQuartersFlag)

model_ruralWhite <- glm(LILATracts_1And10 ~ lawhite10 + TractWhite, family = "binomial", data = df_rural)

summary(model_ruralWhite)
```

```{r}

model_ruralBlack <- glm(LILATracts_1And10 ~ lablack10 + lablack10share + TractBlack, family = "binomial", data = df_rural)
summary(model_ruralBlack)

```

```{r}

model_ruralNHOPI <- glm(LILATracts_1And10 ~ lanhopi10 + lanhopi10share + TractNHOPI, family = "binomial", data = df_rural)
summary(model_ruralNHOPI)

```

```{r}

model_ruralAsian <- glm(LILATracts_1And10 ~ laasian10 + laasian10share + TractAsian, family = "binomial", data = df_rural)
summary(model_ruralAsian)

```

```{r}

model_ruralAian <- glm(LILATracts_1And10 ~ laaian10 + laaian10share + TractAIAN, family = "binomial", data = df_rural)
summary(model_ruralAian)

```

```{r}

model_ruralomultir <- glm(LILATracts_1And10 ~ laomultir10 + laomultir10share + TractOMultir, family = "binomial", data = df_rural)
summary(model_ruralomultir)

```

```{r}

model_ruralhispanic <- glm(LILATracts_1And10 ~ lahisp10 + lahisp10share + TractHispanic, family = "binomial", data = df_rural)
summary(model_ruralhispanic)

```

```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
probwhite=predict(model_ruralWhite, type = "response" )
probblack=predict(model_ruralBlack, type = "response" )
probnhopi=predict(model_ruralNHOPI, type = "response" )
probasian=predict(model_ruralAsian, type = "response" )
probaian=predict(model_ruralAian, type = "response" )
probomultir=predict(model_ruralomultir, type = "response" )
probhisp=predict(model_ruralhispanic, type = "response" )

df_rural$probwhite=probwhite
df_rural$probblack=probblack
df_rural$probnhopi=probnhopi
df_rural$probasian=probasian
df_rural$probaian=probaian
df_rural$probomultir=probomultir
df_rural$probhisp=probhisp

h1 <- roc(LILATracts_1And10~probwhite, data=df_rural)
auc(h1) # area-under-curve prefer 0.8 or higher.

h2 <- roc(LILATracts_1And10~probblack, data=df_rural)
auc(h2)
h3 <- roc(LILATracts_1And10~probnhopi, data=df_rural)
auc(h3)
h4 <- roc(LILATracts_1And10~probasian, data=df_rural)
auc(h4)
h5 <- roc(LILATracts_1And10~probaian, data=df_rural)
auc(h5)
h6 <- roc(LILATracts_1And10~probomultir, data=df_rural)
auc(h6)
h7 <- roc(LILATracts_1And10~probhisp, data=df_rural)
auc(h7)

#plot(h)
# unloadPkg("pROC")
```

```{r HosmerLemeshow}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
admitLogitHoslem = hoslem.test(df$LILATracts_1And10, fitted(model_imp)) # Hosmer and Lemeshow test, a chi-squared test
unloadPkg("ResourceSelection") 
admitLogitHoslem
```

```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
df_demo = df
prob=predict(model_imp, type = "response" )
df_demo$prob=prob
h <- roc(LILATracts_1And10~prob, data=df_demo)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
```

```{r McFadden}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
admitLogitpr2 = pR2(model_imp)
admitLogitpr2
unloadPkg("pscl") 
```
```{r confusionMatrix, results='markup'}
loadPkg("ModelMetrics")
# confusionMatrix(admitLogit)
conf_matrix =confusionMatrix(actual=model_imp$y,predicted=model_imp$fitted.values)
unloadPkg("ModelMetrics")

conf_matrix$
```

## Total:

```{r model}
df$Urban <- factor(df$Urban)

model_White <- glm(LILATracts_1And10 ~ Urban + lawhite1 + lawhite10 + lawhite1share + lawhite10share + TractWhite, family = "binomial", data = df)
summary(model_White)
```
```{r}

model_Black <- glm(LILATracts_1And10 ~ Urban + lablack1share + lablack10share + TractBlack, family = "binomial", data = df)
summary(model_Black)

```

```{r}

model_NHOPI <- glm(LILATracts_1And10 ~ Urban + lanhopi1 + lanhopi1share + lanhopi10 + lanhopi10share + TractNHOPI, family = "binomial", data = df)
summary(model_NHOPI)

```

```{r}

model_Asian <- glm(LILATracts_1And10 ~ Urban + laasian1 + laasian1share + laasian10 + laasian10share + TractAsian, family = "binomial", data = df)
summary(model_Asian)

```

```{r}

model_Aian <- glm(LILATracts_1And10 ~ Urban + laaian1 + laaian10share + TractAIAN, family = "binomial", data = df)
summary(model_Aian)

```

```{r}

model_omultir <- glm(LILATracts_1And10 ~ Urban + laomultir1share + laomultir10 + laomultir10share + TractOMultir, family = "binomial", data = df)
summary(model_omultir)

```

```{r}

model_hispanic <- glm(LILATracts_1And10 ~ Urban + lahisp1 + lahisp1share + lahisp10share + TractHispanic, family = "binomial", data = df)
summary(model_hispanic)

```

```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
df_demo =df
probwhite=predict(model_White, type = "response" )
probblack=predict(model_Black, type = "response" )
probnhopi=predict(model_NHOPI, type = "response" )
probasian=predict(model_Asian, type = "response" )
probaian=predict(model_Aian, type = "response" )
probomultir=predict(model_omultir, type = "response" )
probhisp=predict(model_hispanic, type = "response" )

df_demo$probwhite=probwhite
df_demo$probblack=probblack
df_demo$probnhopi=probnhopi
df_demo$probasian=probasian
df_demo$probaian=probaian
df_demo$probomultir=probomultir
df_demo$probhisp=probhisp

h1 <- roc(LILATracts_1And10~probwhite, data=df_demo)
auc(h1) # area-under-curve prefer 0.8 or higher.

h2 <- roc(LILATracts_1And10~probblack, data=df_demo)
auc(h2)
h3 <- roc(LILATracts_1And10~probnhopi, data=df_demo)
auc(h3)
h4 <- roc(LILATracts_1And10~probasian, data=df_demo)
auc(h4)
h5 <- roc(LILATracts_1And10~probaian, data=df_demo)
auc(h5)
h6 <- roc(LILATracts_1And10~probomultir, data=df_demo)
auc(h6)
h7 <- roc(LILATracts_1And10~probhisp, data=df_demo)
auc(h7)

#plot(h)
# unloadPkg("pROC")
```

## Checking with Final model:


```{r}
model_glm2 <- glm(LILATracts_1And10 ~ OHU2010 + LA1and20 + LATracts10 + LATractsVehicle_20 + GroupQuartersFlag + PovertyRate + HUNVFlag + MedianFamilyIncome + lalowi1share + lakids1share + laaian1share * TractAIAN, family = binomial(link = "logit"), data = df_subset)

# lahisp1share + lawhite1share + lablack1share + laaian1share + laomultir10share + laseniors10share
# TractNHOPI
# laasian10 + TractAsian
# TractHispanic + lahisp1share
# lawhite1share + TractWhite
# lablack1 + TractBlack
# laaian1share + TractAIAN
# laomultir1 + TractOMultir


summary(model_glm2)

predict_model <- predict(model_glm2, df_subset, type='response')
df_subset$pred_model_glm2 <- ifelse(predict_model >= 0.5, 1, 0)
accuracy <- mean((df_subset$pred_model_glm2)== (df_subset$LILATracts_1And10))

accuracy

```

```{r}

cm = table(df_subset$LILATracts_1And10,model_glm2$fitted.values>.5)
xkabledply( table(df_subset$LILATracts_1And10,model_glm2$fitted.values>.5), title = "Confusion matrix from Logit Model" )
round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)
```

The total accuracy (using the default cutoff of 0.5) is `r round(100*(cm[1,1]+cm[2,2])/sum(cm), digits=1)`% which is pretty decent.

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)

ROC and AUC measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The AUC is always between 0.5 and 1.  

```{r }
loadPkg("pROC")
df_demo$prob2=predict(model_glm2, type = c("response")) # Add new column of predicted probabilities
h <- roc(LILATracts_1And10~prob2, data=df_demo)
auc(h)
plot(h)
```






############################################################
# Correlation
############################################################

```{r}
# df <- data.frame(read.csv("FoodDesert2015.csv")) 
#df_corr = subset(df, select = -c(CensusTract, State, County))
df_corr <- subset(df, select = c(TractWhite,TractBlack,TractAsian,TractNHOPI,TractAIAN,TractOMultir,TractHispanic,lawhite10,lawhite10share,lablack10,lablack10share,laasian10,laasian10share,lanhopi10,lanhopi10share,laaian10,laaian10share,laomultir10,laomultir10share,lahisp10,lahisp10share, lawhite1,lawhite1share,lablack1,lablack1share,laasian1,laasian1share,lanhopi1,lanhopi1share,laaian1,laaian1share,laomultir1,laomultir1share,lahisp1,lahisp1share))

correlation_matrix <- cor(df_corr)

# Print the correlation matrix
print(correlation_matrix)

```

```{r}
loadPkg("corrplot")
mtcarscor = cor(df_subset)
corrplot(mtcarscor, method = "number")

```


```{r}

library(ggplot2)
library(dplyr)
df %>%
  filter(LILATracts_1And10 == 1) %>%
  ggplot(aes(x = laomultir1)) +
  geom_histogram(bins = 50,fill = "skyblue", color="darkred") +
  geom_density(alpha = 0.5,fill= "red", color="darkred") +
  labs(title = "Percentage of total population who does not have vehicles in food desert")

```

```{r}
qqnorm(df$lawhite1, main="Q-Q plot of Baseball player heights") 
qqline(df$lawhite1)
#shapiro.test(df$lawhite1) # Shapiro-Wilk test for normality
ks.test(df$lawhite1,pnorm) # Kolmogorov-Smirnov Tests against normal distribution
```

```{r}
mlbclean = outlierKD2(df, laomultir1, rm = TRUE, boxplt = TRUE, qqplt = TRUE)
```

```{r}
mlbclean1 = ezids::outlierKD2(df, PovertyRate, rm = TRUE, boxplt = TRUE, qqplt = TRUE)
```

## Food desert variable importance

```{r}

variable_values <- c(5.9063e-03, 9.9995e-01, 4.3839e+01, 1.0096e+00, 1.0012e+00, 
                     9.9130e-01, 1.0035e+00, 9.9986e-01, 1.0004e+00, 9.9966e-01, 1.0172e+00,
                     1.0005e+00, 9.5884e-02, 9.9924e-01, 1.0006e+00, 1.0006e+00, 1.9875e+00,
                     1.0005e+00, 1.0010e+00, 9.9960e-01, 1.0001e+00, 9.9904e-01, 1.0005e+00)

variable_names <- c("lahunv1share", "MedianFamilyIncome", "Urban1", 
                    "laseniors10", "laomultir1", "TractHUNV", "TractSNAP", "lawhite1",
                    "TractWhite", "TractHispanic", "PovertyRate", "lablack1", 
                    "GroupQuartersFlag1", "lakids1", "lahisp1", "TractAIAN", "PCTGQTRS",
                    "TractOMultir", "lakids10", "TractKids", "TractBlack", "laseniors1",
                    "TractSeniors")
merged_df <- data.frame(Variable = variable_names, Importance = variable_values)
merged_df <- merged_df[order(merged_df$Importance), ]

bar_chart <- ggplot(merged_df, aes(x = variable_names, y = variable_values)) +
  geom_bar(stat = "identity", fill = "lightblue", width = 0.5) +
  labs(title = "Variable importance",
       x = "Variable",
       y = "importance") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.2))  

options(
  repr.plot.width = 25,  # Set the desired width in inches
  repr.plot.height = 30  # Set the desired height in inches
)

print(bar_chart)
```



```{r}
metrics_data <- data.frame(
  Method = c("CART", "CART", "CART", "Logistic", "Logistic", "Logistic"),
  Metric = c("precision", "recall", "accuracy", "precision", "recall", "accuracy"),
  Value = c(0.43029, 0.83996, 0.89117, 0.30786, 0.87071, 0.82149)
)

# Create the line graph using ggplot2
ggplot(metrics_data, aes(x = Metric, y = Value, group = Method, color = Method)) +
  geom_line() +
  geom_point() +
  labs(title = "Comparison of CART and Logistic Metrics",
       x = "Metric",
       y = "Value") +
  theme_minimal()

```

## Poverty rate variable importance

```{r}

variable_values <- c(100, 58.0798, 38.5578, 29.0375, 12.6898, 11.8240, 9.7042, 0, 0, 0)

variable_names <- c("MedianFamilyIncome","LowIncomeTracts","TractSNAP","TractHUNV","TractBlack","TractSeniors","TractWhite", "lahisp","lawhite1","lakids10")
  
merged_df <- data.frame(Variable = variable_names, Importance = variable_values)
merged_df <- merged_df[order(merged_df$Importance), ]

bar_chart <- ggplot(merged_df, aes(x = variable_names, y = variable_values)) +
  geom_bar(stat = "identity", fill = "lightblue", width = 0.5) +
  labs(title = "Variable importance",
       x = "Variable",
       y = "importance") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.2))  

options(
  repr.plot.width = 25,  # Set the desired width in inches
  repr.plot.height = 30  # Set the desired height in inches
)

print(bar_chart)
```

```{r}
metrics_data <- data.frame(
  Method = c("Linear", "Linear", "CART", "CART"),
  Metric = c("R2", "RMSE", "R2", "RMSE"),
  Value = c(0.63682, 7.4614, 0.68551, 6.9420)
)

# Create the line graph using ggplot2
ggplot(metrics_data, aes(x = Metric, y = Value, group = Method, color = Method)) +
  geom_line() +
  geom_point() +
  labs(title = "Comparison of CART and Linear Metrics",
       x = "Metric",
       y = "Value") +
  theme_minimal()

```
